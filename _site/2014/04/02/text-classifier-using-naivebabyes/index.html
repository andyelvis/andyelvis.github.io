<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="andyelvis" />
    <title>使用朴素贝叶斯进行文本分类 | andyelvis</title>
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="/media/css/style.css">
    <link rel="stylesheet" href="/media/css/highlight.css">
    <script type="text/javascript" src="/media/js/jquery-1.7.1.min.js"></script>
	<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </head>
  <script type="text/javascript">
    function setTimeSpan(){
    	var date = new Date();
    	timeSpan.innerText=date.format('yyyy-MM-dd hh:mm:ss');
    }
    
    Date.prototype.format = function(format)
		{
    var o =
    	{
    	    "M+" : this.getMonth()+1, //month
    	    "d+" : this.getDate(),    //day
    	    "h+" : this.getHours(),   //hour
    	    "m+" : this.getMinutes(), //minute
    	    "s+" : this.getSeconds(), //second
    	    "q+" : Math.floor((this.getMonth()+3)/3),  //quarter
    	    "S" : this.getMilliseconds() //millisecond
    	}
    	if(/(y+)/.test(format))
    	format=format.replace(RegExp.$1,(this.getFullYear()+"").substr(4 - RegExp.$1.length));
    	for(var k in o)
    	if(new RegExp("("+ k +")").test(format))
    	format = format.replace(RegExp.$1,RegExp.$1.length==1 ? o[k] : ("00"+ o[k]).substr((""+ o[k]).length));
    	return format;
		}
  </script>
  <body onLoad="setInterval(setTimeSpan,1000);">
    <div id="container">
      <div id="main" role="main">
        <header>
        <h1>使用朴素贝叶斯进行文本分类</h1>
        </header>
        <nav>
        <span><a title="home page" class="" href="/">Home</a></span>
        <span><a title="about" class="" href="/about/">About</a></span>
        <span><a title="guestbook" class="" href="/guestbook/">Guestbook</a></span>
        <span><a title="categories" class="" href="/categories/">Categories</a></span>
        <span><a title="tags" class="" href="/tags/">Tags</a></span>
        <span><a title="links" class="" href="/links/">Links</a></span>
        </nav>
        <article class="content">
        <section class="post">
<h2 id="section">1、文档模型</h2>

<p>一篇文档被表示成一个单词的集合，只关心哪些单词包含在文档中，每个单词出现了多少次，不需要关心单词的顺序。</p>

<p>一篇文档D，属于类C，以邮件垃圾过滤为例，两大类\( C=S(spam) \)和\( C=H(ham) \)。
哪个类有最大的后验概率\( P(C|D) \)，文档D就属于哪个类，使用贝叶斯理论表述如下：
\[ P(C|D)=\frac{P(D|C)P(C)}{P(D)}\propto P(D|C)P(C) \]</p>

<p>有两种文档概率模型，它们都使用朴素贝叶斯假设，将文档看做单词的集合。
这两种模型使用特征向量表示文档，如果一个词表V包含\( |V| \)个不同的单词，那么特征向量维度\( d=|V| \)。</p>

<p><strong>伯努利文档模型：</strong> 文档对应的特征向量的元素由0和1组成，向量每个位置相关联的单词如果出现在文档中，值为1，否则为0.</p>

<p><strong>多项式模型：</strong> 文档对应的特征向量每个位置的值等于相关联的单词出现在文档中的次数。</p>

<p><strong>举例：</strong> 考虑如下的词表：<br />
\[ V=\{blue,red,dog,cat,biscuit,apple\} \]
\( |V|=d=6 \)。假设有这样一篇文档“the blue dog ate a blue biscuit”，\( D^B \)表示伯努利特征向量，\( D^M \)表示多项式特征向量，那么：
\[ D^B=(1,0,1,0,1,0)^T \]
\[ D^M=(2,0,1,0,1,0)^T \]
对文档分类，需要知道指定类下文档的似然估计\( P(D|C) \)以及类的先验概率\( P(C) \)。</p>

<hr />

<h2 id="section-1">2、伯努利模型</h2>

<p>假定有一个词表V，包含\( |V| \)个不同的单词，一个文档向量的第t个位置与词表中的单词\( w_t \)相对应。
\( B_i \)是第i篇文档\( D^i \)的特征向量，\( B_i \)的第t个元素记为\( B_{it} \)，值等于1表示单词\( w_t \)出现在第i篇文档中，等于0表示没有出现。</p>

<p>$P(w_t|C)$表示单词$w_t$出现在类C的文档中的概率，$w_t$不出现在类C文档中的概率等于$1-P(w_t|C)$。
根据贝叶斯假设，每个单词出现在文档中的概率相互独立，文档似然估计$P(D^i|C)$可以表示用各个单词似然$P(w_t|C)$来表示：</p>

<script type="math/tex; mode=display">
P(D^i|C) \sim P(B_i|C) = \prod^{|V|}_{t=1}[B_{it}P(w_t|C)+(1-B_{it})(1-P(w_t|C))]
</script>

<p>如果单词$w_t$出现在文档中，<script type="math/tex">B_{it}=1</script>，相应的概率是$P(w_t|C)$，如果没有出现，$B_{it}=0$，概率是$1-P(w_t|C)$。</p>

<p>$n_k(w_t)$表示在类C=k下，训练文档中出现过单词$w_t$的文档数，$N_k$表示属于类C=k的文档数，那么单词的似然表示如下：</p>

<script type="math/tex; mode=display">
P(w_t|C=k) = \frac{n_k(w_t)}{N_k}
</script>

<p>如果训练数据集总共是N篇文档，那么类C=k的先验概率表示如下：</p>

<script type="math/tex; mode=display">
P(C=k) = \frac{N_k}{N}
</script>

<p>因此给定训练数据集，以及K个类，我们可以按照如下过程建立伯努利文本分类模型：</p>

<p>1、定义词表V，词表包含的单词数量决定了特征向量的维度</p>

<p>2、根据训练数据集，计算如下指标：</p>

<ul>
  <li>N总文档数</li>
  <li>$N_k$属于类C=k的文档数，k=1,……,K</li>
  <li>$n_k(w_t)$类C=k训练文档中出现过单词$w_t$的文档数，需要计算每一个类以及每一个单词</li>
</ul>

<p>3、单词似然估计$P(w_t|C=k)$</p>

<p>4、类先验概率$P(C=k)$</p>

<p>对于未分类文档$D^j$，每个类的后验概率估计如下：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align*}
P(C|D^j)=&P(C|B_j)\\
\propto& P(B_j|C)P(C)\\
\propto& P(C)\prod^{|V|}_{t=1}[B_{jt}P(w_t|C)+(1-B_{jt})(1-P(w_t|C))]
\end{align*}
 %]]></script>

<hr />

<h2 id="section-2">3、多项式分布</h2>

<p>在讨论多项式文档模型之前，需要先熟悉一下多项式分布。</p>

<p>当集合中有些元素无法区分时，我们首先需要这个元素集合的不同排列的个数。例如：从单词“Mississippi”可以产生多少个不同的序列？有11个字母可以用于排列，但是i，s出现了四次，而p出现了两次。如果这些字母都是不重复的，那么将会有11!个排列。然而如果将”i”移除，这些排列中有4!个是相同的。这意味着考虑到i出现过4次，我们可以减少总样本空间的大小。同样的，考虑到s出现4次，p出现2次，m出现1次，不同排列的总数等于：</p>

<script type="math/tex; mode=display">
\frac{11!}{4!4!2!1!} = 34650
</script>

<p>如果一个集合有n个元素，这些元素只有d个不同的值类型，属于类型1的有$n_1$个，类型2的有$n_2$个，类型d的有$n_d$个（$n_1 + n_2 + … + n_d = n$），那么不同的排列数等于：</p>

<script type="math/tex; mode=display">
\frac{n!}{n_1!n_2!...n_d!}
</script>

<p>这些被叫做多项式系数。</p>

<p>假设一个集合包含$d \ge 2$个不同的值类型，元素属于类型t的比率是$p_t$(t=1,…,d)，</p>

<script type="math/tex; mode=display">
\sum^{d}_{t=1}{p_t} = 1 \quad p_t > 0, for \, all \, t.
</script>

<p>假设n个元素是随机出现的，$x_t$表示属于类型t的元素个数，向量$X=(x_1,…,x_d)^T$满足参数为n和$p_1,…,p_d$的多项式分布：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align*}
P(X)=&\frac{n!}{x_1!x_2!...x_d!} {p_1}^{x_1}{p_2}^{x_2}...{p_d}^{x_d}\\
=&\frac{n!}{\prod^{d}_{t=1}x_t!}\prod^{d}_{t=1}{p_t}^{x_t}
\end{align*}
 %]]></script>

<p>$\prod^{d}_{t=1}{p_t}^{x_t}$表示一个序列产生的概率。多项式系数表示有多少个这样的序列。</p>

<hr />

<h2 id="section-3">4、多项式文档模型</h2>

<p>在多项式文档模型中，文档的特征向量不仅仅只关心单词出现与否，还需要关心单词出现的频率。假设$M_i$表示第i篇文档$D^i$的多项式特征向量。
$M_i$的第t个元素，记为<script type="math/tex">M_{it}</script>，它的值等于单词$w_t$出现在文档$D^i$中的次数。<script type="math/tex">n_i=\sum_tM_{it}</script>表示文档$D^i$中所有单词出现的总次数。</p>

<p>$P(w_t|C)$表示单词$w_t$出现在类C中的概率，这里的计算需要用到特征向量中的频率信息。根据朴素贝叶斯假设，每个单词的出现概率相互独立。
我们可以将文档似然估计$P(D^i|C)$表示成一个多项式分布：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align*}
P(D^i|C) \sim P(M_i|C) = &\frac{n_i!}{\prod^{|V|}_{t=1}M_{it}!}\prod^{|V|}_{t=1}{P(w_t|C)}^{M_{it}}\\
\propto&\prod^{|V|}_{t=1}{P(w_t|C)}^{M_{it}}
\end{align*}
 %]]></script>

<p>我们通常不需要关心<script type="math/tex">(n_i! / \prod_tM_{it}!)</script>，因为它不依赖于类C。</p>

<p>假设$z_ik$是一个标记变量，当文档$D^i$属于类C=k时，值等于1，否则等于0。N表示总文档数，那么：</p>

<script type="math/tex; mode=display">
P(w_t|C) = \frac{\sum^{N}_{i=1}M_{it}z_{ik}}{\sum^{|V|}_{s=1}\sum^{N}_{i=1}M_{is}z_{ik}}
</script>

<p>类C=k的先验概率表示如下：</p>

<script type="math/tex; mode=display">
P(C=k) = \frac{N_k}{N}
</script>

<p>因此给定训练数据集，以及K个类，我们可以按照如下过程建立多项式文本分类模型：</p>

<p>1、定义词表V，词表包含的单词数量决定了特征向量的维度</p>

<p>2、根据训练数据集，计算如下指标：</p>

<ul>
  <li>N总文档数</li>
  <li>$N_k$属于类C=k的文档数，k=1,……,K</li>
  <li>$M_{it}$单词$w_t$在文档$D^i$中出现的频率，需要考虑V中的每一个单词</li>
</ul>

<p>3、单词似然估计$P(w_t|C=k)$</p>

<p>4、类先验概率$P(C=k)$</p>

<p>对于未分类文档$D^j$，每个类的后验概率估计如下：</p>

<script type="math/tex; mode=display">% <![CDATA[

\begin{align*}
P(C|D^j)=&P(C|M_j)\\
\propto& P(M_j|C)P(C)\\
\propto& P(C)\prod^{|V|}_{t=1}P(w_t|C)^{M_{it}}
\end{align*}
 %]]></script>

<hr />

<h2 id="section-4">5、零概率问题</h2>

<p>多项式模型的一个缺点是一个单词没有在某个类中出现，会导致零概率问题。因为对于概率乘积，只要有一个乘数因子为0，那么整个乘积结果就会为0。
这意味着一篇文档属于某个类的概率是0，这通常是不可能出现的。</p>

<p>因为一个单词不出现在训练数据中的一个文档类中，并不能说明这个单词不会出现在这个类的任何文档中。</p>

<p>即使单词w没有出现在训练数据的类C=k中，我们仍然要认为$P(w|C=k)&gt;0$。
因为概率之和必须等于1，如果没有观测到的单词的概率被低估了，那么被观测到的单词的概率肯定被高估了。
因此解决这个问题的一个方法就是降低一些被观测到的单词的概率，将这些概率分布到没有观测到的单词上。
解决这个问题的一个比较简单的方式叫做Laplace定律或者加1平滑，如果有W个不同的单词，那么：</p>

<script type="math/tex; mode=display">
P_{Lap}(w_t|C=k) = \frac{1+\sum^{N}_{i=1}M_{it}z_{ik}}{|V|+\sum^{|V|}_{s=1}\sum^{N}_{i=1}M_{is}z_{ik}}
</script>

<p>分子加1，分母加上单词的总个数$|V|$，使得概率仍然是归一化的。</p>

<hr />

<h2 id="section-5">6、比较两个模型</h2>

<p>两个模型有一些区别如下：</p>

<ul>
  <li>文本模型<br />
伯努利：一篇文档可以看做是从一个多维伯努利分布产生而来的。一个单词出现的概率可以看做一次硬币投掷的概率$P(w_t|C)$。<br />
多项式：一篇文档可以看做单词的多项式分布而形成的。文档中的下一个单词出现的概率可以认为是投掷一个有|V|面的色子，每面出现的概率是$P(w_t|C)$。</li>
  <li>文档表示<br />
伯努利：二元向量，元素表示一个单词是否出现。<br />
多项式：整数向量，元素表示一个单词出现的频率。</li>
  <li>单词的多次出现<br />
伯努利：忽略。<br />
多项式：频率计数。</li>
  <li>文档长度<br />
伯努利：更适合于短文档。<br />
多项式：更适合于长文档。</li>
  <li>没有出现的单词<br />
伯努利：影响文档概率。<br />
多项式：不影响文档概率。</li>
</ul>

<hr />

<h2 id="section-6">参考资料</h2>

<ul>
  <li><a href="http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note07-2up.pdf">Text Classification using Naive Bayes</a></li>
</ul>

</section>
<section class="meta">

<br/>
<br/>
<span>
	<a  href="/2014/03/22/jekyll-install-windows/" class="pageNav"  >Previous</a>
	&nbsp;&nbsp;&nbsp;
	<a   class="pageNavInvalid"  >Next</a>
</span>
<hr>
<span class="author">
  <a href="http://andyelvis.github.io">andyelvis</a>
</span>
<span class="time">
  /
  <time datetime="2014-04-02">2014-04-02</time>
</span>
<br />
<span class="license">
  Published under <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">(CC) BY-NC-SA</a>
</span>

<span class="categories">
  in categories
  
  <a href="/categories/#machine learning" title="machine learning">machine learning</a>&nbsp;
  
</span>


<span class="tags">
  tagged with 
  
  <a href="/tags/#naive bayes" title="naive bayes">naive bayes</a>&nbsp;
  
</span>

</section>
<!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"andyelvis"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END -->


        </article>
      </div>

    <footer>
        <p><small>Powered by <a href="https://github.com/mojombo/jekyll">Jekyll</a> & <a href="http://pages.github.com">GitHub</a> | Copyright 2014 - 2014 by <a href="/about/">andyelvis</a> | <span class="label label-info" id="timeSpan"></span></small></p>
    </footer>

    </div>
	
  </body>
</html>
